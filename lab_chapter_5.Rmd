---
title: "Chapter 5: Cross-Validation and the Bootstrap"
output: html_notebook
---

---

### The Validation Set Approach

---

1) Create the train and validation data sets by splitting the original data set in half:

```{r}
library(ISLR)
set.seed(1) # set seed for RNG to ensure reproducibility and repeatability of results
train <- sample(x = 392, size = 192)
```

2) Fit a linear model to the training data:

```{r}
lm_fit_linear <- lm(mpg ~ horsepower, data = Auto, subset = train)
```

3) Use predict() to estimate the response for all 392 observations:

```{r}
pred_linear <- predict(object = lm_fit, newdata = Auto)
```

4) Calculate the MSE for the validation data set:

```{r}
MSE_pred_linear <- mean((Auto$mpg - pred)[-train] ^ 2)
MSE_pred_linear
```

5) Fit a quadratic polynomial hypothesis to the train data:

```{r}
lm_fit_quad <- lm(mpg ~ poly(x = horsepower, degree = 2), 
    data = Auto, subset = train)
```

6) Fit a cubic polynomial hypothesis to the train data:

```{r}
lm_fit_cub <- lm(mpg ~ poly(x = horsepower, degree = 3),
    data = Auto, subset = train)
```

7) Use predict() to estimate the response for the quadratic and cubic regression models:

```{r}
pred_quad <- predict(object = lm_fit_quad, newdata = Auto)
pred_cub <- predict(object = lm_fit_cub, newdata = Auto)
```

8) Calculate the MSE for the quadratic regression model:

```{r}
MSE_pred_quad <- mean((Auto$mpg - pred_quad)[-train] ^ 2)
MSE_pred_quad
```

9) Calculate the MSE for the cubic regression model:

```{r}
MSE_pred_cub <- mean((Auto$mpg - pred_cub)[-train] ^ 2)
MSE_pred_cub
```

10) Try a different training set on the models above and you will obtain somewhat different errors on the validation sets. 

---

### Leave-One-Out Cross-Validation

---

Note that if you use `glm()` without the `family` argument, it will perform linear regression, i.e.:

```{r}
glm_fit_linear <- glm(mpg ~ horsepower, data = Auto)
coef(glm_fit_linear)
```

```{r}
lm_fit_linear <- lm(mpg ~ horsepower, data = Auto)
coef(lm_fit_linear)
```

To perform LOOCV you can use `cv.glm()` from the `boot` package:

```{r}
library(boot)
glm_fit_linear <- glm(mpg ~ horsepower, data = Auto)
cv_err <- cv.glm(data = Auto, glmfit = glm_fit_linear)
cv_err$delta
```

For increasilgly complex polynomial fits, use a for loop in fitting and validating the model:

```{r}
cv_error <- rep(0,5) # initial cv_error to 0's
for (i in 1:5) {
    glm_fit <- glm(mpg ~ poly(x = horsepower, degree = i), data = Auto)
    cv_error[i] <- cv.glm(data = Auto, glmfit = glm_fit)$delta[1]
}

cv_error
```

---

### k-Fold Cross-Validation

---

The `cv.glm()` function from the `boot` package can also be used to implement k-fold cross-validation:

```{r}
set.seed(17)
cv_error_kf <- rep(0, 10)
for (i in 1:10) {
    glm_fit <- glm(mpg ~ poly(x = horsepower, degree = i), data = Auto)
    cv_error_kf[i] <- cv.glm(data = Auto, glmfit = glm_fit, K = 10)$delta[1]
}

cv_error_kf
```

---

### The Bootstrap - Estimating the Accuracty of a Statistic 

---

Estimating the value of alpha that minimizes the risk in a portfolio optimization problemusing the Portfolio dataset in the ISLR package:

1) Create a function that calculates the test statistic of interest (provided on p. 187)

```{r}
estimate_alpha <- function(data, index){
    X = data$X[index]
    Y = data$Y[index]
    (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
```

2) Create a bootstrap sample using `sample()` function:

```{r}
set.seed(1)
index <- sample(x = 1:100, size = 100, replace = TRUE) # use replace = TRUE in sample() to perform bootstrapping
estimate_alpha(data = Portfolio, index = index)
```

3) Implement a bootstrap by performing the above command many times and calculating the standard deviation of the values for alpha:

```{r}
set.seed(20)
alpha_values <- rep(0, 1000) # initialize alpha values to 0
for (i in 1:1000) {
    index <- sample(x = 1:100, size = 100, replace = TRUE) 
    alpha_values[i] <- estimate_alpha(data = Portfolio, index = index)
}

sd(alpha_values)
mean(alpha_values)
```

or use the `boot()` function from the `boot` package:

```{r}
boot(data = Portfolio, statistic = estimate_alpha, R = 10000)
```

---

### The Bootstrap - Estimating the Accuracy of a Linear Regression Model

---

Use the bootstrap approach to assess the variability of the coefficient estimates and predictions from the linear and quadratic regression models concerning the `Auto` dataset:

1) Create a function to model coefficiencts from the lm():

```{r}
calculate_lm <- function (data, index){
    coef(lm(mpg ~ horsepower, data = data, subset = index))
}
```

2) Create a bootstrap estimate using the cacluate_lm function:

```{r}
index <- sample(x = 1:392, size = 392, replace = TRUE)
calculate_lm(data = Auto, index = index)
```

```{r}
index <- sample(x = 1:392, size = 392, replace = TRUE)
calculate_lm(data = Auto, index = index)
```

3) Use `boot()` function to calculate the std errors of 1000 bootstrap estimates for the slope and intercept terms:

```{r}
boot(data = Auto, statistic = calculate_lm, R = 1000)
```

4) Check the bootstrap estimates against the normal equation estimates:

```{r}
summary(lm(mpg ~ horsepower, data = Auto))$coef
```

The standard errors are not the same.  This is due to the data having a non-linear trend. The bootstrap is actually closer to the true value.

5) Check the bootstrap estimates for the quadratic model:

```{r}
calculate_lm_quad <- function(data, index){
    coefficients(lm(mpg ~ horsepower + I(horsepower ^ 2), data = data, subset = index))
}
set.seed(1)
boot(data = Auto, statistic = calculate_lm_quad, R = 1000)
```

6) Check the coefficient estimates from the normal equation:

```{r}
summary(lm(mpg ~ horsepower + I(horsepower ^ 2), data = Auto))$coef
```

Now there is better correspondence between the two approaches.

